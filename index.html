<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<script>
function showMore() {
    var listData = Array.prototype.slice.call(document.querySelectorAll('#dataList li:not(.shown)')).slice(0, 9);

    for (var i=0; i < listData.length; i++) {
        listData[i].className = 'shown';
        listData[i].style.display = 'list-item';
    }
    switchButtons();
}

function switchButtons() {
    var hiddenElements = Array.prototype.slice.call(document.querySelectorAll('#dataList li:not(.shown)'));
    if(hiddenElements.length == 0) {
        document.getElementById('moreButton').style.display = 'none';
    } else {
        document.getElementById('moreButton').style.display = 'block';
    }

    var shownElements = Array.prototype.slice.call(document.querySelectorAll('#dataList li:not(.hidden)'));
    if(shownElements.length == 0) {
        document.getElementById('lessButton').style.display = 'none';
    } else {
        document.getElementById('lessButton').style.display = 'block';
    }
}

window.onload = function(){
    showMore();
}
</script>

  <title>Chuong (Vance) Nguyen</title>
  <meta name="author" content="Chuong (Vance) Nguyen">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <main>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <h1 style="text-align:center">Chuong (Vance) Nguyen</h1>
              <p>I am a Ph.D. in Robotics in the <a href="https://ame.usc.edu/">Department of Aerospace and Mechanical Engineering</a> at <a href="https://www.usc.edu/">University of Southern California, Los Angeles</a>. I work at the <a href="https://sites.usc.edu/quann/">Dynamic Robotics and Control Laboratory</a> and am fortunate to be advised by Prof. <a href="https://ame.usc.edu/directory/faculty/profile/?lname=Nguyen&fname=Quan">Quan Nguyen</a>. I obtained my M.S. degrees from University of Southern California and Gwangju Institute of Science and Technology.
              </p>
              <p> I am honored to receive Viterbi Fellowship and AME Department Fellowship from USC. I am fortunate to collaborate with Prof. <a href="https://natanaso.github.io/"> Nikolay Atanasov</a> (UC San Diego), Dr. <a href="https://scholar.google.co.kr/citations?user=YDimn5wAAAAJ&hl=en"> Guillaume Bellegarda</a> (EPFL, Switzerland), and Dr. <a href="https://thaipduong.github.io/"> Thai Duong</a> (Rice University).
              </p>
              <p style="text-align:center">
                <a href="mailto:vanchuong.nguyen@usc.edu">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.co.kr/citations?user=eF7sD5IAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/nguyenvchuong/">Github</a> <!-- &nbsp/&nbsp
                  <a href="https://thaipduong.github.io/my2cents/">Blog</a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile/avatar2025.jpeg"><img style="width:100%;max-width:100%" alt="Profile photo of Chuong (Vance) Nguyen" src="images/profile/avatar2025.png" class="hoverZoomLink circular-image"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <h2>Recent News</h2>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <ul id="dataList">
<!--           <li class="hidden">[Nov 2022] I served on the Program Commitee for the <a href="https://aaai.org/Conferences/AAAI-23/"> AAAI'23 </a> workshop  <a href="https://machinelearning-dynamic.github.io/"> "When Machine Learning meets Dynamical Systems". </a> </li>-->
              <li class="hidden">[Jun 2025] I started my job as robotic research and software engineer at <a href="https://www.ghostrobotics.io/"> Ghost Robotics</a> to develop solution for enhancing robustness and agility for legged locomotion. </li>             
              <li class="hidden">[Feb 2025] I started my internship at <a href="https://www.fieldai.com/"> Field AI</a> to build up solution for last-mile package delievery for Amazon using legged robots.</li>             
              <li class="hidden">[Feb 2025] Our paper on <a href="https://www.youtube.com/watch?v=z4HzWtGu9RM"> Variational Integrator Discretized Trajectory Optimization for Legged Maneuvers</a> is accepted to ICRA 2025.</li>             
              <li class="hidden">[Feb 2025] Our paper on <a href="https://arxiv.org/pdf/2408.02619"> Iterative Learning Control for Dynamic Maneuvers on Legged Robots </a> is accepted to ICRA 2025.</li>
              <li class="hidden">[Nov 2024] Our paper on <a href="https://arxiv.org/pdf/2407.14749"> Variable-Frequency Model Learning and Predictive Control for Legged Robots </a> is accepted to Robotics And Automation Letter 2024.</li>
              <li class="hidden">[Oct 2024] Our paper on <a href="https://arxiv.org/pdf/2011.07089.pdf"> Deep Reinforcement Learning for Robust Jumping on Legged Robots </a> is accepted to Robotics And Autonomous Systems Journal 2024.</li>
              <li class="hidden">[Aug 2023] Our paper on <a href="https://arxiv.org/pdf/2011.07089.pdf"> Deep Reinforcement Learning for Robust Jumping on Legged Robots </a> is submitted to Robotics And Autonomous Systems Journal.</li>
              <li class="hidden">[Aug 2023] I TA'ed at AME301: Dynamics. </li>
              <li class="hidden">[Sep 2022] I gave a presentation on <a href="https://arxiv.org/pdf/2110.06764.pdf"> Contact-timing and Trajectory Optimization for 3D Jumping on Quadruped Robots </a> at <a href="https://ras.papercept.net/conferences/conferences/IROS22/program/IROS22_ContentListWeb_4.html#web-19_07"> IROS'22. </a> </li>
              <li class="hidden">[July 2022] Our paper on <a href="https://arxiv.org/abs/2204.01147">Continuous Jumping for Legged Robots</a> has been accepted to <a href="https://cdc2022.ieeecss.org/"> CDC 2022 </a>. &#x1F389;&#x1F389;&#x1F389;&#x1F389;&#x1F389;</li>
              <li class="hidden">[Jun 2022] Our paper on Optimize 3D jumping on quadruped robots has been accepted to <a href="https://ieeexplore.ieee.org/document/9981284">IROS 2022</a>. &#x1F389;&#x1F389;&#x1F389;&#x1F389;&#x1F389;</li>
              <li class="hidden">[Jan 2021] I TA'ed at AME599: Dynamic Robotics and Control. </li>
              <li class="hidden">[Sep 2020] I am honored to receive Viterbi Fellowship and AME Department Fellowship from the <a href="https://ame.usc.edu/">AME Department</a>.</li>
              <li class="hidden">[Sep 2020] I started my Ph.D. journey in the <a href="https://ame.usc.edu/">AME Department</a> at <a href="https://www.usc.edu/">University of Southern California</a>.</li>
            <input id="moreButton" type="button" value="More..." onclick="showMore()"/>
            </ul>
            
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <h2>Research Areas</h2>
              <p>
                Optimization, control, learning, perceptions approaches for dynamic robotics including trajectory optimization, deep learning, and real-time optimization-based control.
              </p>
            </td>
          </tr>
        </tbody></table>
            
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <h2>Publications and Research Projects</h2>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <b>OPTIMIZATION and CONTROL</b>
                </td>
            </tr>
          </tbody></table>   


              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <td style="padding:20px;width:30%;vertical-align:top">
                  <img src='images/ilc/Introduction.png' width="220">
                 <video  width="220" muted autoplay loop>
                   <source src="images/ilc/d50h30_from40cmmemory.mp4" type="video/mp4">
                   Your browser does not support the video tag.
                   </video>
                    <!--              <video  width="220" muted autoplay loop>-->
                    <!--                <source src="images/skm/skm_map3.mp4" type="video/mp4">-->
                    <!--                Your browser does not support the video tag.-->
                    <!--                </video>-->
               </td>

               <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://www.youtube.com/watch?v=zbEB5bMBgY0">
                  <h3>Mastering Agile Jumping Skills from Simple Practices with Iterative Learning Control</h3>
                </a>
                <br>
                <strong>Chuong Nguyen*</strong>, Lingfan Bao*, Quan Nguyen
                <!-- <a href="https://sites.usc.edu/quann/">Quan Nguyen</a> -->
                <br>
                <em>ICRA 2025. *Equal contribution</em>
                <br>
  <!--              <a href="https://thaipduong.github.io/kernelbasedmap/">website</a> /-->
                <a href="https://www.youtube.com/watch?v=zbEB5bMBgY0">video</a>
                <a href="https://arxiv.org/pdf/2408.02619">arXiv</a>
                <p></p>
                <p> Achieving precise target jumping with legged robots
                  poses a significant challenge due to the long flight phase and
                  the uncertainties inherent in contact dynamics and hardware.
                  Forcefully attempting these agile motions on hardware could
                  result in severe failures and potential damage. Motivated by these
                  challenging problems, we propose an Iterative Learning Control
                  (ILC) approach that aims to learn and refine jumping skills from
                  easy to difficult, instead of directly learning these challenging
                  tasks. We verify that learning from simplicity can enhance safety
                  and target jumping accuracy over trials. Compared to other ILC
                  approaches for legged locomotion, our method can tackle the
                  problem of a long flight phase where control input is not available.
                  In addition, our approach allows the robot to apply what it learns
                  from a simple jumping task to accomplish more challenging tasks
                  within a few trials directly in hardware, instead of learning from
                  scratch. </p>
                  <img src='images/ilc/simple-complex-short.png' width="580">
              </td>
              </tr>

              </tbody></table>


              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <td style="padding:20px;width:30%;vertical-align:top">
                  <!-- <img src='images/ilc/Introduction.png' width="220"> -->
                 <video  width="220" muted autoplay loop>
                   <source src="images/VI-TO/backflip.mp4" type="video/mp4">
                   Your browser does not support the video tag.
                   </video>
                  <video  width="220" muted autoplay loop>
                    <source src="images/VI-TO/combinatino.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                    </video>
               </td>

               <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://www.youtube.com/watch?v=z4HzWtGu9RM">
                  <h3>High Accuracy Aerial Maneuvers on Legged Robots
                    using Variational Integrator Discretized Trajectory Optimization</h3>
                </a>
                <br>
                Scott Beck*, <strong>Chuong Nguyen*</strong>, Thai Duong, Nikolay Atanasov, Quan Nguyen
                <!-- <a href="https://sites.usc.edu/quann/">Quan Nguyen</a> -->
                <br>
                <em>ICRA 2025. *Equal contribution</em>
                <br>
  <!--              <a href="https://thaipduong.github.io/kernelbasedmap/">website</a> /-->
                <a href="https://www.youtube.com/watch?v=z4HzWtGu9RM">video</a> /
                <a href="https://github.com/DRCL-USC/VI_discretized_TO">Code</a> /
                <p></p>
                <p> Performing acrobatic maneuvers involving long
                  aerial phases, such as precise dives or multiple backflips from
                  significant heights, remains an open challenge in legged robot
                  autonomy. Such aggressive motions often require accurate state
                  predictions over long horizons with multiple contacts and
                  extended flight phases. We propose a novel whole-body
                  TO method using variational integration (VI) and full-body
                  nonlinear dynamics for long-flight aggressive maneuvers. Compared to traditional Euler-based TO, our approach using VI
                  preserves energy and momentum properties of the continuous 
                  time system and reduces error between predicted and executed
                  trajectories by factors of between 2 − 10 while achieving
                  similar planning time. We successfully demonstrate long-flight
                  triple backflips on a quadruped A1 robot model and backflips
                  on a bipedal HECTOR robot model for various heights and
                  distances, achieving landing angle errors of only a few degrees. </p>
                  <!-- <img src='images/ilc/simple-complex-short.png' width="580"> -->
              </td>
              </tr>

              </tbody></table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top">
              <img src='images/3djump/gif/barrel_roll/double-roll-normal-speed.gif' width="220">
<!--               <br>-->
<!--                 <img src='images/3djump/gif/double_flip/double_backflip_v2.gif' width="220">-->
<!--                 <br>-->
                 <p> <center> The <i style="color:green">first ever double barrel roll</i>  achieved by A1 robot</center></p>
            </td>

            <td style="padding:20px;width:80%;vertical-align:middle">
<!--              <a href="https://thaipduong.github.io/SE3HamDL/">-->
              <a href="https://www.youtube.com/watch?v=d7RcWEXTbqc&feature=youtu.be">
                  <h3>Contact-timing and Trajectory Optimization for 3D Jumping on Quadruped Robots</h3>
              </a>
              <br>
              <strong>Chuong Nguyen</strong>, Quan Nguyen
              <!-- <a href="https://sites.usc.edu/quann/">Quan Nguyen</a> -->
              <br>
              <em>IROS</em>, 2022.
              <br>
<!--              <a href="https://thaipduong.github.io/SE3HamDL/">website</a> /-->
              <a href="https://www.youtube.com/watch?v=d7RcWEXTbqc&feature=youtu.be">video</a> /
              <a href="https://arxiv.org/pdf/2110.06764.pdf">arXiv</a>
              <p></p>
              <p>Performing highly agile acrobatic motions with a long flight phase requires perfect timing, high accuracy, and coordination of the full-body motion. 
              To address these challenges, we present a novel approach on timings and trajectory optimization framework for legged robots performing aggressive 3D jumping. 
              In our method, we firstly utilize an effective optimization framework using simplified rigid body dynamics to solve for contact timings and a reference trajectory of the robot body. 
              The solution of this module is then used to formulate a full-body trajectory optimization based on the full nonlinear dynamics of the robot. 
              This combination allows us to effectively optimize for contact timings while ensuring that the jumping trajectory can be effectively realized in the robot hardware. 
              We first validate the efficiency of the proposed framework on the A1 robot model for various 3D jumping tasks such as double-backflips off the high altitude of 2m. 
              Experimental validation was then successfully conducted for various aggressive 3D jumping motions such as diagonal jumps, barrel roll, and double barrel roll from a box of heights 0.4m and 0.9m, respectively.</p>
<!--                <img src='images/se3hamdl/gif/data2.gif' width="180">-->
<!--                <img src='images/se3hamdl/gif/data11.gif' width="180">-->
<!--                <img src='images/se3hamdl/gif/data15.gif' width="180">-->
<!--                <br>-->
<!--                <img src='images/se3hamdl/gif/data14.gif' width="180">-->
<!--                <img src='images/se3hamdl/gif/data13.gif' width="180">-->
<!--                <img src='images/se3hamdl/gif/data3.gif' width="180">-->
<!--                <p><center>Data collection from manual flights</center></p>-->
            </td>
          </tr>

          </tbody></table>


             <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top">
              <img src='images/continuous_jump/Introduction.png' width="220">
                 <img src='images/continuous_jump/random_distance_crop.gif' width="220">
                 <img src='images/continuous_jump/unknown_mass_crop.gif' width="220">
<!--               <br>-->
<!--                 <img src='images/3djump/gif/double_flip/double_backflip_v2.gif' width="220">-->
<!--                 <br>-->
<!--                 <p> <center> The <i style="color:green">first double barrel roll</i>  achieved by A1 robot</center></p>-->
            </td>
            <td style="padding:20px;width:80%;vertical-align:middle">
              <a href="https://www.youtube.com/watch?v=jBGY1K1UbhM">
                  <h3>Continuous jumping for legged robots on stepping stones via trajectory optimization and model predictive control</h3>
              </a>
              <br>
              <strong>Chuong Nguyen</strong>, Lingfan Bao, Quan Nguyen
              <!-- <a href="https://sites.usc.edu/quann/">Quan Nguyen</a> -->
              <br>
              <em>CDC</em>, 2022.
              <br>
<!--              <a href="https://thaipduong.github.io/SE3HamDL/">website</a> /-->
              <a href="https://www.youtube.com/watch?v=jBGY1K1UbhM">video</a> /
              <a href="https://arxiv.org/pdf/2204.01147.pdf">arXiv</a>
              <p></p>
              <p>Performing highly agile dynamic motions, such as
              jumping or running on uneven stepping stones has remained
              a challenging problem in legged robot locomotion. This paper
              presents a framework that combines trajectory optimization
              and model predictive control to perform robust and consecutive
              jumping on stepping stones. In our approach, we first utilize
              trajectory optimization based on full-nonlinear dynamics of
              the robot to generate periodic jumping trajectories for various
              jumping distances. A jumping controller based on a model
              predictive control is then designed for realizing smooth jumping
              transitions, enabling the robot to achieve continuous jumps on
              stepping stones. Thanks to the incorporation of MPC as a
              real-time feedback controller, the proposed framework is also
              validated to be robust to uneven platforms with unknown height
              perturbations and model uncertainty on the robot dynamics.</p>
<!--                <img src='images/continuous_jump/random_distance.gif' width="580">-->
                <img src='images/continuous_jump/random_height_distance.gif' width="580">
<!--                <img src='images/continuous_jump/unknown_mass.gif' width="580">-->
<!--                <img src='images/se3hamdl/gif/data15.gif' width="180">-->
<!--                <br>-->
<!--                <img src='images/se3hamdl/gif/data14.gif' width="180">-->
<!--                <img src='images/se3hamdl/gif/data13.gif' width="180">-->
<!--                <img src='images/se3hamdl/gif/data3.gif' width="180">-->
<!--                <p><center>Data collection from manual flights</center></p>-->
            </td>
          </tr>

          </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <b>ROBOT LEARNING</b>
                </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <td style="padding:20px;width:30%;vertical-align:top">
              <!-- <img src='images/drl/Introduction.png' width="220"> -->
            <video  width="220" muted autoplay loop>
              <source src="images/learning-mpc/continuous_60cm.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video>
            <video  width="220" muted autoplay loop>
              <source src="images/learning-mpc/combination.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video>
              <!-- <p> <center> <i style="color:green">Robustness</i>  to environment noise of foot disturbances</center></p> -->
          </td>

          <td style="padding:20px;width:80%;vertical-align:middle">
            <a href="https://www.youtube.com/watch?v=yUqI_MBOC6Q">
                <h3>Variable-Frequency Model Learning and Predictive Control for Jumping Maneuvers on Legged Robots</h3>
            </a>
            <br>
              <strong>Chuong Nguyen </strong>, Abdullah Altawaitan, Thai Duong, Nikolay Atanasov, Quan Nguyen
            <!-- <a href="https://sites.usc.edu/quann/">Quan Nguyen</a> -->
            <br>
            <em>Robotics and Automation Letters (RAL) 2024 and ICRA 2025</em>,
            <br>
<!--              <a href="https://thaipduong.github.io/sbkm/">website</a> /-->
            <a href="https://www.youtube.com/watch?v=yUqI_MBOC6Q">video</a> /
            <a href="https://arxiv.org/pdf/2407.14749">arXiv</a> /
            <a href="https://github.com/DRCL-USC/Learning_MPC_Jumping">Code</a>
            <p></p>
            <p> Achieving both target accuracy and robustness
              in dynamic maneuvers with long flight phases has been a significant challenge for legged
              robots. We propose a novel learningbased control approach consisting of model learning and
              model predictive control (MPC) utilizing an adaptive frequency
              scheme. We learn a
              model directly from experiments, accounting not only for leg
              dynamics but also for modeling errors and unknown dynamics mismatch in hardware and during contact. 
              Additionally, learning the model with adaptive frequency allows us to cover
              the entire flight phase and final jumping target, enhancing
              the prediction accuracy of the jumping trajectory. Using the
              learned model, we also design an adaptive-frequency MPC to
              effectively leverage different jumping phases and track the
              target accurately. 
              <!-- In hardware experiments with a Unitree A1
              robot, we demonstrate that our approach outperforms baseline
              MPC using a nominal model, reducing the jumping distance
              error up to 8 times. We achieve jumping distance errors of less
              than 3% during continuous jumping on uneven terrain with
              randomly-placed perturbations of random heights. Our approach obtains
              distance errors of 1−2 cm on 34 single and continuous jumps
              with different jumping targets and model uncertainties. -->
            </p>
          <!-- <img src='images/drl/framework.png' width="580"> -->
          </td>
        <!-- </tr> -->
      </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:30%;vertical-align:top">
                <img src='images/drl/Introduction.png' width="220">
              <video  width="220" muted autoplay loop>
                <source src="images/drl/d70_h10.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              <video  width="220" muted autoplay loop>
                <source src="images/drl/d60_h20.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
                <p> <center> <i style="color:green">Robustness</i>  to environment noise of foot disturbances</center></p>
            </td>

            <td style="padding:20px;width:80%;vertical-align:middle">
              <a href="https://www.youtube.com/watch?v=cihIFsPvy-Y">
                  <h3>Robust Quadruped Jumping via Deep Reinforcement Learning</h3>
              </a>
              <br>
              <!-- <a href="https://scholar.google.co.kr/citations?user=YDimn5wAAAAJ&hl=en">Guillaume Bellegarda*</a>, -->
                Guillaume Bellegarda*,
                <strong>Chuong Nguyen*</strong>, Quan Nguyen
              <!-- <a href="https://sites.usc.edu/quann/">Quan Nguyen</a> -->
              <br>
              <em>Robotics and Autonomous Systems Journal (RAS), 2024. *Equal contribution</em>,
              <br>
<!--              <a href="https://thaipduong.github.io/sbkm/">website</a> /-->
              <a href="https://www.youtube.com/watch?v=cihIFsPvy-Y">video</a> /
              <a href="https://arxiv.org/pdf/2011.07089.pdf">arXiv</a>
              <p></p>
              <p> In this paper, we consider a general task of
              jumping varying distances and heights for a quadrupedal robot
              in noisy environments, such as off of uneven terrain and with
              variable robot dynamics parameters. To accurately jump in such
              conditions, we propose a framework using deep reinforcement
              learning that leverages and augments the complex solution of
              nonlinear trajectory optimization for quadrupedal jumping.
              While the standalone optimization limits jumping to take-off from
              flat ground and requires accurate assumptions of robot dynamics,
              our proposed approach improves the robustness to allow jumping
              off of significantly uneven terrain with variable robot dynamical
              parameters and environmental conditions. Compared with
              walking and running, the realization of aggressive jumping on
              hardware necessitates accounting for the motors’ torque-speed
              relationship as well as the robot’s total power limits. By
              incorporating these constraints into our learning framework, we
              successfully deploy our policy sim-to-real without further tuning,
              fully exploiting the available onboard power supply and motors.
              We demonstrate robustness to environment noise of foot disturbances of up to 6 cm in height, or 33% of the robot’s nominal
              standing height, while jumping 2x the body length in distance.</p>
            <img src='images/drl/framework.png' width="580">
            </td>
          <!-- </tr> -->
        </tbody></table>



      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                  <h2>Industrial Projects</h2>
              </td>
          </tr>
      </tbody></table>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:30%;vertical-align:top">
         <video  width="220" muted autoplay loop>
           <source src="images/industry/rov.mp4" type="video/mp4">
           Your browser does not support the video tag.
           </video>
            <!--              <video  width="220" muted autoplay loop>-->
            <!--                <source src="images/skm/skm_map3.mp4" type="video/mp4">-->
            <!--                Your browser does not support the video tag.-->
            <!--                </video>-->
       </td>

       <td style="padding:20px;width:75%;vertical-align:middle">
        <h3>Inspection offshore constructions under deepsea</h3>
        <em>Robotic Engineer & ROV Pilot (PTSC & SMD)</em>
        <br>
        <p></p>
        <p> As a Robotic Engineer and ROV Pilot, I specialize in the deployment and operation of remotely operated vehicles (ROVs) for offshore construction and deep-sea inspection.
          My responsibilities include planning and executing underwater missions to inspect subsea pipelines, structures, and assets in challenging environments.
          I integrate and maintain advanced robotic systems, sensors, and manipulators to ensure precise and reliable data collection.
          During offshore operations, I work closely with multidisciplinary teams to provide real-time visuals and diagnostics for structural integrity assessments.
          I also troubleshoot and repair ROV systems on-site, minimizing downtime and ensuring mission success.
          My experience spans over +10 industrial offshore projects, where I have contributed to both construction support and routine maintenance inspections at significant ocean depths.. </p>
      </td>
      </tr>

      </tbody></table>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:30%;vertical-align:top">
         <video  width="220" muted autoplay loop>
           <source src="images/industry/trafficID.mp4" type="video/mp4">
           Your browser does not support the video tag.
           </video>
            <!--              <video  width="220" muted autoplay loop>-->
            <!--                <source src="images/skm/skm_map3.mp4" type="video/mp4">-->
            <!--                Your browser does not support the video tag.-->
            <!--                </video>-->
       </td>

       <td style="padding:20px;width:75%;vertical-align:middle">
        <h3>Object detection and tracking for traffic application</h3>
        <em>AI and Computer Vision Engineer</em>
        <br>
        <p></p>
        <p> I have hands-on experience as an AI and Computer Vision Engineer, specializing in deep learning techniques for object detection and tracking. 
          My work focuses on traffic applications, where I developed models to detect and track vehicles, pedestrians, and traffic violations in real time. I have implemented and optimized convolutional neural networks (CNNs) using Yolo for robust performance in complex urban environments. 
          My projects involved dataset preparation, model training, evaluation, and deployment on edge devices. 
          The project requires programming kills in Python, Tensorflow, and OpenCV. </p>
      </td>
      </tr>

      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <p style="text-align:right;font-size:small;">
                <a href='https://clustrmaps.com/site/1b3ld'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=160&t=tt&d=w2RjAUmBU2UblwclHzT7CYrfKyZjpWjsOPSaxaDFbgI'/></a>
                <br /> 
                Template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  </main>
</body>

</html>
